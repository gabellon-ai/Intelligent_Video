# Core ML
torch>=2.2.0
torchvision>=0.17.0
transformers>=4.40.0
accelerate>=0.27.0

# Vision models
supervision>=0.19.0
groundingdino-py>=0.4.0
segment-anything-2>=0.1.0

# Image processing
opencv-python>=4.9.0
pillow>=10.0.0
numpy>=1.26.0

# OCR
paddleocr>=2.7.0
paddlepaddle>=2.6.0

# Utilities
tqdm>=4.66.0
pyyaml>=6.0.0
requests>=2.31.0

# =============================================================================
# TensorRT Optimization (Optional - for NVIDIA GPUs)
# =============================================================================
# For maximum performance on NVIDIA hardware, install TensorRT:
#
# Option 1: NGC PyTorch container (recommended for DGX)
#   docker pull nvcr.io/nvidia/pytorch:24.01-py3
#   # TensorRT and torch-tensorrt are pre-installed
#
# Option 2: Manual installation
#   pip install tensorrt torch-tensorrt --extra-index-url https://download.pytorch.org/whl/cu121
#
# Option 3: torch.compile fallback (works without TensorRT)
#   pip install triton  # Linux only, auto-installs with torch on Linux
#
# The system will automatically detect available backends:
# 1. TensorRT (via torch-tensorrt) - ~10x speedup
# 2. torch.compile with inductor - ~2-3x speedup
# 3. Eager mode - baseline (no optimization)
# =============================================================================

# Linux-only torch.compile backend (auto-fallback if TensorRT unavailable)
triton>=2.1.0; platform_system == "Linux"
